{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-shahd-h/Financial-Risk-prediction-using-Feature-selection/blob/main/RandomForest_Feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwiQcDX62MXv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx1sUujR2wXE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P_I9NLw20ap"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=[\"id\"], errors=\"ignore\")\n",
        "\n",
        "\n",
        "X = df.drop(\"Bankrupt?\", axis=1)\n",
        "y = df[\"Bankrupt?\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHb3Jxom3CB_"
      },
      "source": [
        "#Random **Forest** without Feature Selection\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrftKANL20XM",
        "outputId": "70481727-4161-46c5-f769-f7adaca0503c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Baseline Model (بدون Feature Selection):\n",
            "\n",
            "Accuracy:  0.9677\n",
            "Precision: 1.0000\n",
            "Recall:    0.1373\n",
            "F1 Score:  0.2414\n",
            "\n",
            " Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98      1313\n",
            "           1       1.00      0.14      0.24        51\n",
            "\n",
            "    accuracy                           0.97      1364\n",
            "   macro avg       0.98      0.57      0.61      1364\n",
            "weighted avg       0.97      0.97      0.96      1364\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Training a Random Forest model on all features\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on the test data\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Performance evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "#  the results\n",
        "print(\" Baseline Model (بدون Feature Selection):\\n\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "\n",
        "# Detailed report\n",
        "print(\"\\n Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bilPprQV3OG0"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "#Genetic Algorithm Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZedSb0IU3NTO",
        "outputId": "b52c1583-edd3-40ea-8bf3-2a4174c70957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n",
            "Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6u5a7gCb20UJ",
        "outputId": "2f8384d3-2760-42a6-9d31-7c76134ed0b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Number of selected features: 54\n",
            " Selected feature indices: [1, 3, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 23, 24, 25, 30, 31, 33, 35, 37, 39, 40, 42, 45, 47, 48, 50, 51, 53, 54, 56, 57, 59, 62, 63, 65, 66, 68, 70, 71, 72, 76, 77, 78, 79, 80, 82, 83, 84, 86, 89, 92]\n",
            "\n",
            " Selected Feature Names:\n",
            "[' ROA(A) before interest and % after tax', ' Operating Gross Margin', ' Operating Profit Rate', ' Pre-tax net Interest Rate', ' Non-industry income and expenditure/revenue', ' Continuous interest rate (after tax)', ' Operating Expense Rate', ' Research and development expense rate', ' Interest-bearing debt interest rate', ' Net Value Per Share (B)', ' Net Value Per Share (A)', ' Net Value Per Share (C)', ' Cash Flow Per Share', ' Revenue Per Share (Yuan ¥)', ' Realized Sales Gross Profit Growth Rate', ' Operating Profit Growth Rate', ' After-tax Net Profit Growth Rate', ' Total Asset Return Growth Rate Ratio', ' Cash Reinvestment %', ' Quick Ratio', ' Total debt/Total net worth', ' Net worth/Assets', ' Borrowing dependency', ' Contingent liabilities/Net worth', ' Net profit before tax/Paid-in capital', ' Accounts Receivable Turnover', ' Inventory Turnover Rate (times)', ' Fixed Assets Turnover Frequency', ' Revenue per person', ' Operating profit per person', ' Working Capital to Total Assets', ' Quick Assets/Total Assets', ' Cash/Total Assets', ' Quick Assets/Current Liability', ' Current Liability to Assets', ' Inventory/Current Liability', ' Current Liabilities/Liability', ' Current Liabilities/Equity', ' Long-term Liability to Current Assets', ' Total income/Total expense', ' Current Asset Turnover Rate', ' Quick Asset Turnover Rate', ' Working capitcal Turnover Rate', ' Current Liability to Liability', ' Current Liability to Equity', ' Equity to Long-term Liability', ' Cash Flow to Total Assets', ' Cash Flow to Liability', ' Cash Flow to Equity', ' Current Liability to Current Assets', ' Liability-Assets Flag', ' Total assets to GNP price', \" Net Income to Stockholder's Equity\", ' Interest Coverage Ratio (Interest expense to EBIT)']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from deap import base, creator, tools\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# GA\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_bool\", lambda: random.randint(0, 1))\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# fitness function\n",
        "def evalFitness(individual):\n",
        "    selected_features = [i for i in range(len(individual)) if individual[i] == 1]\n",
        "    if len(selected_features) == 0:\n",
        "        return 0.0,\n",
        "    clf = RandomForestClassifier(random_state=42)\n",
        "    clf.fit(X_train[:, selected_features], y_train)\n",
        "    pred = clf.predict(X_test[:, selected_features])\n",
        "    acc = accuracy_score(y_test, pred)\n",
        "    return acc,\n",
        "\n",
        "toolbox.register(\"evaluate\", evalFitness)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "# GA running\n",
        "def run_ga():\n",
        "    pop = toolbox.population(n=30)\n",
        "    NGEN = 20\n",
        "    for gen in range(NGEN):\n",
        "        offspring = toolbox.select(pop, len(pop))\n",
        "        offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "            if random.random() < 0.5:\n",
        "                toolbox.mate(child1, child2)\n",
        "                del child1.fitness.values\n",
        "                del child2.fitness.values\n",
        "\n",
        "        for mutant in offspring:\n",
        "            if random.random() < 0.2:\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        pop[:] = offspring\n",
        "\n",
        "    top_individual = tools.selBest(pop, 1)[0]\n",
        "    selected_features = [i for i in range(len(top_individual)) if top_individual[i] == 1]\n",
        "    return selected_features\n",
        "\n",
        "# Running GA and selecting features\n",
        "ga_selected_features = run_ga()\n",
        "print(f\"\\n Number of selected features: {len(ga_selected_features)}\")\n",
        "print(f\" Selected feature indices: {ga_selected_features}\")\n",
        "\n",
        "# Printing the names of the selected columns\n",
        "selected_column_names = X.columns[ga_selected_features]\n",
        "print(\"\\n Selected Feature Names:\")\n",
        "print(selected_column_names.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnVAyiHB3VaH"
      },
      "source": [
        "#Performance Evaluation of Random Forest Using GA-Selected Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h9zSaezg3XMJ",
        "outputId": "a75e5cab-5014-4ecb-f8a4-d4149630cb7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Performance After GA Feature Selection:\n",
            "\n",
            "Accuracy:  0.9699\n",
            "Precision: 1.0000\n",
            "Recall:    0.1961\n",
            "F1 Score:  0.3279\n",
            "\n",
            " Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98      1313\n",
            "           1       1.00      0.20      0.33        51\n",
            "\n",
            "    accuracy                           0.97      1364\n",
            "   macro avg       0.98      0.60      0.66      1364\n",
            "weighted avg       0.97      0.97      0.96      1364\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training the model using only the selected columns\n",
        "\n",
        "rf_ga = RandomForestClassifier(random_state=42)\n",
        "rf_ga.fit(X_train[:, ga_selected_features], y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_ga = rf_ga.predict(X_test[:, ga_selected_features])\n",
        "\n",
        "# Performance evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "accuracy_ga = accuracy_score(y_test, y_pred_ga)\n",
        "precision_ga = precision_score(y_test, y_pred_ga)\n",
        "recall_ga = recall_score(y_test, y_pred_ga)\n",
        "f1_ga = f1_score(y_test, y_pred_ga)\n",
        "\n",
        "# Displaying the results\n",
        "print(\" Performance After GA Feature Selection:\\n\")\n",
        "print(f\"Accuracy:  {accuracy_ga:.4f}\")\n",
        "print(f\"Precision: {precision_ga:.4f}\")\n",
        "print(f\"Recall:    {recall_ga:.4f}\")\n",
        "print(f\"F1 Score:  {f1_ga:.4f}\")\n",
        "\n",
        "print(\"\\n Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_ga))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U86zkf-a3aOB"
      },
      "source": [
        "# Applying Particle Swarm Optimization (PSO) to Select Best Features for Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kpMDeg6C3Z1p",
        "outputId": "fd940607-0c16-4728-a51b-78e2350cc60f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.15.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pyswarms) (3.10.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from pyswarms) (25.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pyswarms) (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pyswarms) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.17.0)\n",
            "Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyswarms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XgyaSRt3f4J"
      },
      "source": [
        "#PSO Feature Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcj4mUA03gxh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pyswarms as ps\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Defining the evaluation function for each feature set\n",
        "def pso_objective_function(particles):\n",
        "    n_particles = particles.shape[0]\n",
        "    scores = []\n",
        "\n",
        "    for i in range(n_particles):\n",
        "        # Selected features map\n",
        "        mask = particles[i] > 0.5\n",
        "        if np.sum(mask) == 0:\n",
        "            scores.append(1.0)  # Penalty if there are no features\n",
        "\n",
        "            continue\n",
        "\n",
        "      # Training and evaluating Random Forest\n",
        "        clf = RandomForestClassifier(random_state=42)\n",
        "        clf.fit(X_train[:, mask], y_train)\n",
        "        pred = clf.predict(X_test[:, mask])\n",
        "        acc = 1.0 - accuracy_score(y_test, pred)  #PSO performs minimization, so we invert the value.\n",
        "\n",
        "        scores.append(acc)\n",
        "\n",
        "    return np.array(scores)\n",
        "\n",
        "# PSO settings (with mandatory 'k' and 'p')\n",
        "options = {\n",
        "    'c1': 2,\n",
        "    'c2': 2,\n",
        "    'w': 0.9,\n",
        "    'k': 5,  # Number of neighbors\n",
        "    'p': 2   # Probability\n",
        "}\n",
        "\n",
        "#Number of features = number of columns in the data\n",
        "dimensions = X_train.shape[1]\n",
        "\n",
        "# Creating a PSO object\n",
        "optimizer = ps.discrete.BinaryPSO(n_particles=30, dimensions=dimensions, options=options)\n",
        "\n",
        "# Running PSO\n",
        "best_cost, best_pos = optimizer.optimize(pso_objective_function, iters=20)\n",
        "\n",
        "# Extracting the selected columns\n",
        "pso_selected_features = np.where(best_pos > 0.5)[0]\n",
        "print(f\"\\n PSO Selected Features ({len(pso_selected_features)}):\")\n",
        "print(pso_selected_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilbo8_Sj3fPB"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO8xg1vj3lHH"
      },
      "source": [
        "# Evaluation code after PSO Feature Selection:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlgmnK-R3l_l"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Training Random Forest using the features selected by PSO\n",
        "rf_pso = RandomForestClassifier(random_state=42)\n",
        "rf_pso.fit(X_train[:, pso_selected_features], y_train)\n",
        "\n",
        "# Predicting on the test set\n",
        "y_pred_pso = rf_pso.predict(X_test[:, pso_selected_features])\n",
        "\n",
        "# Calculating performance\n",
        "accuracy_pso = accuracy_score(y_test, y_pred_pso)\n",
        "precision_pso = precision_score(y_test, y_pred_pso)\n",
        "recall_pso = recall_score(y_test, y_pred_pso)\n",
        "f1_pso = f1_score(y_test, y_pred_pso)\n",
        "\n",
        "# Displaying the results\n",
        "print(\" Performance After PSO Feature Selection:\\n\")\n",
        "print(f\"Accuracy:  {accuracy_pso:.4f}\")\n",
        "print(f\"Precision: {precision_pso:.4f}\")\n",
        "print(f\"Recall:    {recall_pso:.4f}\")\n",
        "print(f\"F1 Score:  {f1_pso:.4f}\")\n",
        "\n",
        "# Detailed report\n",
        "print(\"\\n Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_pso))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eqw6zzC3pf8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ==== Replace these with your actual values ====\n",
        "# Baseline model\n",
        "accuracy_base = 0.9640\n",
        "precision_base = 0.8571\n",
        "recall_base = 0.1463\n",
        "f1_base = 0.2500\n",
        "\n",
        "# After GA Feature Selection\n",
        "accuracy_ga =  0.9680\n",
        "precision_ga = 0.9091\n",
        "recall_ga = 0.2439\n",
        "f1_ga = 0.3846\n",
        "\n",
        "# After PSO Feature Selection\n",
        "accuracy_pso = 0.9690\n",
        "precision_pso = 1.0000\n",
        "recall_pso =  0.2439\n",
        "f1_pso =  0.3922\n",
        "\n",
        "# ==============================================\n",
        "\n",
        "# Metrics and values\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "baseline = [accuracy_base, precision_base, recall_base, f1_base]\n",
        "ga = [accuracy_ga, precision_ga, recall_ga, f1_ga]\n",
        "pso = [accuracy_pso, precision_pso, recall_pso, f1_pso]\n",
        "\n",
        "x = np.arange(len(metrics))  # label locations\n",
        "width = 0.25  # bar width\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bar1 = ax.bar(x - width, baseline, width, label='Baseline')\n",
        "bar2 = ax.bar(x, ga, width, label='GA Feature Selection')\n",
        "bar3 = ax.bar(x + width, pso, width, label='PSO Feature Selection')\n",
        "\n",
        "# Labels and titles\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Performance Comparison Before and After Feature Selection')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.set_ylim(0, 1.05)\n",
        "ax.legend()\n",
        "\n",
        "# Annotate function\n",
        "def annotate_bars(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                    xytext=(0, 3),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "# Add value annotations\n",
        "annotate_bars(bar1)\n",
        "annotate_bars(bar2)\n",
        "annotate_bars(bar3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}